# streamlit_app.py
# ì„¤ì¹˜: pip install streamlit google-generativeai gTTS pillow pandas
# ì‹¤í–‰: streamlit run streamlit_app.py

import os, io, json, time, tempfile
import streamlit as st
import pandas as pd
from PIL import Image, ImageDraw
from gtts import gTTS

# ==== API í‚¤ ìë™ ê°ì§€ (secrets â†’ env â†’ ìƒìˆ˜) ====
API_KEY = (
    st.secrets.get("GOOGLE_API_KEY", "")
    if hasattr(st, "secrets") else ""
) or os.getenv("GOOGLE_API_KEY", "") or ""  # <- ë§ˆì§€ë§‰ì— ì§ì ‘ ë¬¸ìì—´ë¡œ ë„£ì–´ë„ ë¨

# ---- LLM(ì˜µì…˜) ì´ˆê¸°í™” ----
USE_LLM = False
MODEL = None
if API_KEY:
    try:
        import google.generativeai as genai
        genai.configure(api_key=API_KEY)
        MODEL = genai.GenerativeModel("gemini-1.5-flash-latest")
        USE_LLM = True
    except Exception as e:
        USE_LLM = False

# ---- ìƒ˜í”Œ ë£° & ê±°ë˜ ----
SAMPLE_RULES = [
    {"name":"Alpha Card","mcc":["FNB","CAFE"],"rate":0.05,"cap":20000},
    {"name":"Beta Card","mcc":["ALL"],"rate":0.02,"cap":50000},
    {"name":"Cinema Max","mcc":["CINE"],"rate":0.10,"cap":15000},
]
SAMPLE_TX = pd.DataFrame([
    {"date":"2025-08-28","merchant":"ìŠ¤íƒ€ì»¤í”¼ ë³¸ì ","mcc":"CAFE","amount":4800},
    {"date":"2025-08-29","merchant":"ê¹€ë°¥ì™•","mcc":"FNB","amount":8200},
    {"date":"2025-08-30","merchant":"ë©”ê°€ì‹œë„¤ë§ˆ ê±´ëŒ€","mcc":"CINE","amount":12000},
    {"date":"2025-09-01","merchant":"ë²„ê±°íŒ°ë¦¬ìŠ¤","mcc":"FNB","amount":8700},
    {"date":"2025-09-02","merchant":"ì¹´í˜ë¼ë–¼ë©","mcc":"CAFE","amount":5100},
])

DEPT_MAP = {
    "ë¯¼ì›":"ê³ ê°ë³´í˜¸ì„¼í„°", "ì¹´ë“œ":"ì¹´ë“œìƒë‹´ì„¼í„°", "ëŒ€ì¶œ":"ì—¬ì‹ ìƒë‹´ì„¼í„°",
    "ì—°ê¸ˆ":"ì—°ê¸ˆÂ·ì„¸ì œìƒë‹´", "ì„¸ì œ":"ì—°ê¸ˆÂ·ì„¸ì œìƒë‹´",
    "ìƒë‹´ìš”ì²­":"ì¢…í•©ìƒë‹´", "ê¸°íƒ€":"ì¢…í•©ìƒë‹´"
}

# ---- ìœ í‹¸ ----
def draw_avatar(size=320):
    img = Image.new("RGBA", (size, size), (245, 248, 255, 255))
    d = ImageDraw.Draw(img)
    d.ellipse((size*0.18, size*0.05, size*0.82, size*0.65),
              fill=(220,230,255), outline=(100,110,180), width=4)
    d.rectangle((size*0.31, size*0.55, size*0.69, size*0.95),
                fill=(210,220,255), outline=(100,110,180), width=4)
    return img

def safe_json_loads(s, default):
    try:
        return json.loads(s)
    except Exception:
        return default

def tts_to_mp3_bytes(text: str):
    try:
        buf = io.BytesIO()
        gTTS(text=text, lang='ko').write_to_fp(buf)
        return buf.getvalue()
    except Exception:
        return None

# ---- LLM ë³´ì¡° ----
def llm_summary(text: str) -> str:
    if USE_LLM and MODEL:
        try:
            prompt = f"ë‹¤ìŒ ê³ ê°ì˜ ë¯¼ì›/ë¬¸ì˜ ë‚´ìš©ì„ ìƒë‹´ì‚¬ê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ 3ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½:\n\n{text}"
            res = MODEL.generate_content(prompt)
            return getattr(res, "text", str(res)).strip()
        except Exception as e:
            return f"[LLM ì˜¤ë¥˜: {e}]"
    return "ìš”ì•½(ë°ëª¨): í•µì‹¬ ìŸì ê³¼ ìš”ì²­ì‚¬í•­ì„ ê°„ë‹¨íˆ ì •ë¦¬í•´ ìƒë‹´ì‚¬ì—ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤."

def llm_classify(text: str) -> dict:
    if USE_LLM and MODEL:
        tmpl = ("JSONìœ¼ë¡œë§Œ ë‹µí•´. keys=[intent, sub_intent, urgency]. "
                "intent in [ë¯¼ì›, ì¹´ë“œ, ëŒ€ì¶œ, ì—°ê¸ˆ, ì„¸ì œ, ìƒë‹´ìš”ì²­, ê¸°íƒ€]; urgency in [ë‚®ìŒ, ë³´í†µ, ë†’ìŒ]")
        try:
            res = MODEL.generate_content(f"{tmpl}\n\nì‚¬ìš©ì ë°œí™”:\n{text}")
            return safe_json_loads(getattr(res, "text", "{}"), {"intent":"ê¸°íƒ€","sub_intent":"ë¶„ë¥˜ì˜¤ë¥˜","urgency":"ë³´í†µ"})
        except Exception as e:
            return {"intent":"ê¸°íƒ€","sub_intent":f"LLM ì˜¤ë¥˜: {e}", "urgency":"ë³´í†µ"}
    # ê·œì¹™ ê¸°ë°˜ ë°ëª¨ ë¶„ë¥˜
    q = text
    if any(k in q for k in ["ê¸ˆë¦¬","ë¯¼ì›","ë¶ˆë§Œ"]):
        return {"intent":"ë¯¼ì›","sub_intent":"ê¸ˆë¦¬/í‘œê¸° ì´ìŠˆ","urgency":"ë³´í†µ"}
    if any(k in q for k in ["ì¹´ë“œ","í˜œíƒ"]):
        return {"intent":"ì¹´ë“œ","sub_intent":"í˜œíƒë¬¸ì˜","urgency":"ë³´í†µ"}
    if "ëŒ€ì¶œ" in q or "ê°ˆì•„íƒ€" in q:
        return {"intent":"ëŒ€ì¶œ","sub_intent":"ê°ˆì•„íƒ€ê¸°","urgency":"ë³´í†µ"}
    if any(k in q for k in ["ì—°ê¸ˆ","ì„¸ì•¡","ì†Œë“ê³µì œ","ì„¸ì œ"]):
        return {"intent":"ì„¸ì œ","sub_intent":"ì—°ê¸ˆ/ì„¸ì œ ë¬¸ì˜","urgency":"ë³´í†µ"}
    if any(k in q for k in ["ì „í™”","ìƒë‹´","ì½œë°±"]):
        return {"intent":"ìƒë‹´ìš”ì²­","sub_intent":"ì½œë°±","urgency":"ë³´í†µ"}
    return {"intent":"ê¸°íƒ€","sub_intent":"ì¼ë°˜ ë¬¸ì˜","urgency":"ë³´í†µ"}

def build_handoff(summary: str, cls: dict) -> dict:
    dept = DEPT_MAP.get(cls.get("intent","ê¸°íƒ€"), "ì¢…í•©ìƒë‹´")
    return {
        "target_department": dept,
        "callback_enabled": True,
        "priority": 2 if cls.get("urgency")=="ë†’ìŒ" else 1,
        "context_summary": summary,
        "recommendation_basis": f"{cls.get('intent')}/{cls.get('sub_intent')}",
        "version": "poc-0.1",
        "ts": int(time.time())
    }

def estimate_saving(amount: int, mcc: str, rules: list, month_usage: dict):
    best = ("í˜„ì¬ì¹´ë“œ ìœ ì§€", 0, "ì¶”ê°€ í˜œíƒ ì—†ìŒ")
    for r in rules:
        if "ALL" not in r.get("mcc", []) and mcc not in r.get("mcc", []):
            continue
        rate = float(r.get("rate", 0.0))
        cap  = int(r.get("cap", 99999999))
        used = int(month_usage.get(r["name"], 0))
        remain = max(0, cap - used)
        save = min(int(amount * rate), remain)
        if save > best[1]:
            best = (r["name"], save, f"{r['name']} {int(rate*100)}% / ì”ì—¬í•œë„ {remain:,}ì›")
    return best

# ---- ììœ  ëŒ€í™” (ì˜µì…˜) ----
def gemini_chat(history, user_msg):
    if not (USE_LLM and MODEL):
        return history + [("system", "LLM í‚¤ê°€ ì—†ì–´ì„œ ë°ëª¨ì—ì„œëŠ” ììœ  ëŒ€í™”ê°€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")]
    # historyëŠ” [(role, text), ...]
    msgs = []
    for role, text in history:
        prefix = "User: " if role == "user" else "Assistant: "
        msgs.append(prefix + text)
    msgs.append("User: " + user_msg)
    prompt = "\n".join(msgs) + "\nAssistant:"
    try:
        res = MODEL.generate_content(prompt)
        reply = getattr(res, "text", str(res)).strip()
    except Exception as e:
        reply = f"[ëŒ€í™” ì˜¤ë¥˜: {e}]"
    return history + [("user", user_msg), ("assistant", reply)]

# ---- UI ----
st.set_page_config(page_title="ì•„ë°”íƒ€ ê¸ˆìœµ ì½”ì¹˜ PoC", page_icon="ğŸ’¬", layout="centered")

with st.sidebar:
    st.title("ì•„ë°”íƒ€")
    st.image(draw_avatar(), caption="ê¸ˆìœµ ì½”ì¹˜")
    st.markdown(f"**LLM ëª¨ë“œ:** {'âœ… (í‚¤ ì‚¬ìš©)' if USE_LLM else 'âŒ (ë°ëª¨ ê·œì¹™)'}")
    st.caption("â€» ì‹¤ì œ ê²°ì œ/ì§€ì˜¤íœì‹±/CRM ì—°ë™ì€ ë³„ë„ ì‹œìŠ¤í…œÂ·ê¶Œí•œ í•„ìš”")

st.title("ì•„ë°”íƒ€í˜• ê¸ˆìœµ ì½”ì¹˜ â€“ PoC")

tab1, tab2, tab3 = st.tabs(["â‘  ìš”ì•½Â·ë¶„ë¥˜Â·í•¸ë“œì˜¤í”„", "â‘¡ ê²°ì œ ì§ì „ ì¹´ë“œ ì¶”ì²œ", "â‘¢ ììœ  ëŒ€í™”(ì˜µì…˜)"])

with tab1:
    user_text = st.text_area("ê³ ê°ì˜ ê³ ë¯¼/ë¬¸ì˜ ì…ë ¥",
        value="ì§€ë‚œë‹¬ 15ì¼ 100ë§Œì› ì •ê¸°ì˜ˆê¸ˆ 3.5%ë¡œ ë“¤ì—ˆëŠ”ë° ì•±ì—ëŠ” 3.2%ë¡œ ë³´ì…ë‹ˆë‹¤.", height=140)
    if st.button("ìš”ì•½ & ë¶„ë¥˜ & í•¸ë“œì˜¤í”„ ìƒì„±", type="primary"):
        summary = llm_summary(user_text)
        cls = llm_classify(user_text)
        handoff = build_handoff(summary, cls)

        c1, c2 = st.columns(2)
        with c1:
            st.subheader("ìš”ì•½")
            st.write(summary)
            st.subheader("ì˜ë„ ë¶„ë¥˜")
            st.json(cls, expanded=False)
        with c2:
            st.subheader("ìƒë‹´ì‚¬ í•¸ë“œì˜¤í”„ í˜ì´ë¡œë“œ")
            st.json(handoff, expanded=False)
            coach_text = "ë§ì”€ ê°ì‚¬í•©ë‹ˆë‹¤. ìš”ì•½Â·ë¶„ë¥˜ ê²°ê³¼ë¥¼ ìƒë‹´ì‚¬ì—ê²Œ ì •í™•íˆ ì „ë‹¬í•˜ê² ìŠµë‹ˆë‹¤. ì½œë°±ë„ ì˜ˆì•½ ê°€ëŠ¥í•´ìš”."
            if st.toggle("ê°ì • ì½”ì¹­ ë©˜íŠ¸ ìŒì„± ë“£ê¸°", value=False):
                audio_bytes = tts_to_mp3_bytes(coach_text)
                if audio_bytes:
                    st.audio(audio_bytes, format="audio/mp3")
                else:
                    st.warning("TTS ìƒì„± ì˜¤ë¥˜")

with tab2:
    st.caption("ê¸ˆì•¡Â·ì—…ì¢…ì„ ì…ë ¥í•˜ë©´ ë£°(JSON)ì— ë”°ë¼ ì˜ˆìƒ ì ˆì•½ì•¡ì„ ê³„ì‚°í•©ë‹ˆë‹¤.")
    left, right = st.columns([1,1])
    with left:
        amount = st.number_input("ê²°ì œ ê¸ˆì•¡(ì›)", min_value=0, value=48000, step=1000)
        mcc = st.selectbox("ì—…ì¢…(MCC)", ["FNB","CAFE","CINE","ALL"], index=0)
        usage_text = st.text_input("ì´ë²ˆë‹¬ ì¹´ë“œë³„ ëˆ„ì  ì ë¦½(JSON)", value='{"Alpha Card": 5000}')
    with right:
        rules_text = st.text_area("ì¹´ë“œ ë£°(JSON)", value=json.dumps(SAMPLE_RULES, ensure_ascii=False, indent=2), height=180)

    if st.button("ìµœì  ì¹´ë“œ ì¶”ì²œ"):
        rules = safe_json_loads(rules_text, SAMPLE_RULES)
        usage = safe_json_loads(usage_text, {})
        name, save, reason = estimate_saving(int(amount), mcc, rules, usage)
        if save > 0:
            st.success(f"ì¶”ì²œ: {name} | ì˜ˆìƒ ì ˆì•½ì•¡: {save:,}ì›")
            st.caption(reason)
        else:
            st.info("ì¶”ê°€ ì ˆì•½ íš¨ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì¹´ë“œë¥¼ ìœ ì§€í•˜ì„¸ìš”.")

with tab3:
    st.caption("Gemini í‚¤ê°€ ì„¤ì •ëœ ê²½ìš°ì—ë§Œ í™œì„±í™”ë©ë‹ˆë‹¤.")
    if "chat_hist" not in st.session_state:
        st.session_state.chat_hist = []  # [(role, text), ...]

    for role, text in st.session_state.chat_hist:
        with st.chat_message("user" if role=="user" else "assistant"):
            st.markdown(text)

    if not USE_LLM:
        st.info("LLM í‚¤ê°€ ì—†ì–´ ììœ  ëŒ€í™”ëŠ” ë¹„í™œì„±í™” ìƒíƒœì…ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì˜ LLM ëª¨ë“œ í‘œì‹œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    else:
        if msg := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
            st.session_state.chat_hist = gemini_chat(st.session_state.chat_hist, msg)
            # rerun to render the new messages
            st.rerun()

st.markdown("---")
st.caption("Free ê¸°ì¤€: í‚¤ê°€ ì—†ìœ¼ë©´ PoC ê¸°ëŠ¥(ìš”ì•½/ë¶„ë¥˜ëŠ” ë°ëª¨ ê·œì¹™, ì¹´ë“œ ì¶”ì²œì€ ë¡œì»¬ ë£°)ìœ¼ë¡œ ì‹œì—° ê°€ëŠ¥í•©ë‹ˆë‹¤.")
